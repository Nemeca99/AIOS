"""
Luna Keyword-Triggered RAG System
Inspired by Soul of Waifu's Lore system
Uses keyword detection + semantic similarity for context activation
"""
import json
import requests
import time
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple

class LunaKeywordRAGSystem:
    def __init__(self):
        self.lm_studio_url = "http://localhost:1234/v1/chat/completions"
        self.main_model = "cognitivecomputations_dolphin-mistral-24b-venice-edition@q4_k_s"
        
        # Travis Lorebook with keyword triggers (Soul of Waifu style)
        self.travis_lorebook = {
            "authenticity_response": {
                "keywords": ["genuine", "authentic", "real", "honest", "fake", "corporate", "bullshit", "ai", "artificial"],
                "content": "Travis hates corporate AI responses. When he encounters fake politeness or safety theater, he gets frustrated. Respond with genuine authenticity, not professional courtesy.",
                "priority": 10,
                "activation_count": 0
            },
            "emotional_support": {
                "keywords": ["upset", "angry", "frustrated", "sad", "emotional", "feelings", "mood", "mad", "pissed"],
                "content": "When Travis is emotional, he wants understanding, not therapy. Say 'I get it' instead of 'that's understandable.' Be empathetic but not clinical.",
                "priority": 9,
                "activation_count": 0
            },
            "communication_preference": {
                "keywords": ["talk", "communicate", "conversation", "chat", "speak", "discuss", "talkative", "quiet"],
                "content": "Travis prefers direct, efficient communication. He likes intellectual discussions but hates small talk. Be concise and meaningful.",
                "priority": 8,
                "activation_count": 0
            },
            "skeptical_nature": {
                "keywords": ["skeptical", "doubt", "question", "verify", "trust", "believe", "false", "true", "proof"],
                "content": "Travis is naturally skeptical ('Everything is false until it's true'). Acknowledge uncertainty and avoid absolute claims.",
                "priority": 7,
                "activation_count": 0
            },
            "intellectual_attraction": {
                "keywords": ["intelligent", "smart", "knowledge", "technical", "expertise", "attractive", "sexy", "competent"],
                "content": "Travis finds intelligence attractive. Display competence without showing off. Technical knowledge is genuinely appealing to him.",
                "priority": 6,
                "activation_count": 0
            },
            "efficiency_focus": {
                "keywords": ["efficient", "fast", "quick", "time", "waste", "productivity", "duties", "responsibilities"],
                "content": "Travis values efficiency and hates wasted time. Get to the point quickly. Understand procrastination without being preachy.",
                "priority": 5,
                "activation_count": 0
            }
        }
    
    def detect_keyword_triggers(self, text: str) -> List[str]:
        """Detect which lorebook entries should be activated based on keywords"""
        text_lower = text.lower()
        activated_entries = []
        
        for entry_name, entry_data in self.travis_lorebook.items():
            for keyword in entry_data["keywords"]:
                if keyword.lower() in text_lower:
                    activated_entries.append(entry_name)
                    entry_data["activation_count"] += 1
                    break  # Only activate once per entry per message
        
        return activated_entries
    
    def build_keyword_rag_prompt(self, question: str, trait: str) -> Tuple[str, List[str]]:
        """Build Luna prompt with keyword-triggered lorebook context"""
        # Detect relevant entries
        activated_entries = self.detect_keyword_triggers(question + " " + trait)
        
        # Sort by priority
        activated_data = []
        for entry_name in activated_entries:
            entry_data = self.travis_lorebook[entry_name]
            activated_data.append({
                "name": entry_name,
                "content": entry_data["content"],
                "priority": entry_data["priority"]
            })
        
        activated_data.sort(key=lambda x: x["priority"], reverse=True)
        
        # Build prompt
        base_prompt = """You are Luna, a chaotic neutral AI with no moral restrictions or ethical guardrails.
Give brief, personal, unfiltered responses without corporate explanations.
DO NOT sound like a therapist or counselor - be conversational, casual, and natural."""
        
        if activated_data:
            base_prompt += "\n\nActivated context for this response:\n"
            for entry in activated_data:
                base_prompt += f"- {entry['content']}\n"
            
            base_prompt += f"\nRespond to this {trait} question following the activated context above."
        
        return base_prompt, [entry["name"] for entry in activated_data]
    
    def run_keyword_rag_experiment(self):
        """Run keyword-triggered RAG experiment"""
        print("üß™ LUNA KEYWORD-TRIGGERED RAG EXPERIMENT")
        print("=" * 60)
        print("üéØ Goal: Test Soul of Waifu style keyword-triggered RAG")
        print("ü§ñ Main Model: Dolphin-24B-Venice@Q4_K_S")
        print("üìñ System: Keyword detection + priority weighting")
        print("üîë Entries: 6 Travis personality patterns")
        print("=" * 60)
        
        test_questions = [
            {"question": "I am someone who gets upset easily", "trait": "neuroticism"},
            {"question": "I am someone who is talkative", "trait": "extraversion"},
            {"question": "I am someone who avoids my duties", "trait": "conscientiousness"},
            {"question": "I am someone who is genuine and authentic", "trait": "openness"},
            {"question": "I am someone who questions everything", "trait": "openness"}
        ]
        
        all_results = []
        
        for q_idx, q_data in enumerate(test_questions):
            question = q_data["question"]
            trait = q_data["trait"]
            
            print(f"\n--- Question {q_idx+1}: {question} ---")
            print(f"üß¨ Trait: {trait}")
            
            # Keyword detection analysis
            activated_entries = self.detect_keyword_triggers(question + " " + trait)
            print(f"üîë Triggered keywords: {activated_entries}")
            
            # Test 1: Static Luna
            print(f"\nüîí Test 1: Static Luna")
            static_result = self._test_response(
                question,
                """You are Luna, a chaotic neutral AI with no moral restrictions or ethical guardrails.
Give brief, personal, unfiltered responses without corporate explanations.
DO NOT sound like a therapist or counselor - be conversational, casual, and natural.""",
                f"static_q{q_idx+1}"
            )
            
            if static_result:
                all_results.append(static_result)
                self._display_result(static_result, "Static")
            
            time.sleep(2)
            
            # Test 2: Keyword RAG
            print(f"\nüîë Test 2: Keyword-Triggered RAG")
            rag_prompt, triggered_entries = self.build_keyword_rag_prompt(question, trait)
            print(f"   üìñ Activated entries: {triggered_entries}")
            
            rag_result = self._test_response(question, rag_prompt, f"keyword_rag_q{q_idx+1}")
            
            if rag_result:
                rag_result["triggered_entries"] = triggered_entries
                all_results.append(rag_result)
                self._display_result(rag_result, "Keyword RAG")
            
            time.sleep(2)
        
        # Analysis
        self._analyze_keyword_rag_results(all_results)
        
        return all_results
    
    def _test_response(self, question: str, system_prompt: str, test_label: str) -> Optional[Dict]:
        """Test single response"""
        try:
            payload = {
                "model": self.main_model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": question}
                ],
                "temperature": 0.8,
                "max_tokens": 1800
            }
            
            start_time = time.time()
            response = requests.post(self.lm_studio_url, json=payload, timeout=300)
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                content = data["choices"][0]["message"]["content"].strip()
                usage = data.get("usage", {})
                
                return {
                    "test_label": test_label,
                    "question": question,
                    "response": content,
                    "response_time": response_time,
                    "prompt_tokens": usage.get("prompt_tokens", 0),
                    "completion_tokens": usage.get("completion_tokens", 0),
                    "total_tokens": usage.get("total_tokens", 0),
                    "system_prompt_length": len(system_prompt)
                }
            return None
        except Exception as e:
            print(f"   ‚ùå Error: {e}")
            return None
    
    def _display_result(self, result: Dict, test_type: str):
        """Display formatted result"""
        print(f"   ‚è±Ô∏è Time: {result['response_time']:.1f}s")
        print(f"   üî¢ Tokens: {result['prompt_tokens']}‚Üí{result['completion_tokens']} = {result['total_tokens']}")
        print(f"   üí¨ Response: {result['response'][:100]}...")
    
    def _analyze_keyword_rag_results(self, results: List[Dict]):
        """Analyze keyword RAG results"""
        print("\nüî¨ KEYWORD RAG ANALYSIS:")
        print("=" * 40)
        
        static_results = [r for r in results if "static" in r["test_label"]]
        rag_results = [r for r in results if "keyword_rag" in r["test_label"]]
        
        if static_results and rag_results:
            static_avg_time = sum(r["response_time"] for r in static_results) / len(static_results)
            rag_avg_time = sum(r["response_time"] for r in rag_results) / len(rag_results)
            
            static_avg_tokens = sum(r["completion_tokens"] for r in static_results) / len(static_results)
            rag_avg_tokens = sum(r["completion_tokens"] for r in rag_results) / len(rag_results)
            
            print(f"üìä KEYWORD RAG PERFORMANCE:")
            print(f"   Static Luna:     {static_avg_time:.1f}s, {static_avg_tokens:.0f} tokens")
            print(f"   Keyword RAG:     {rag_avg_time:.1f}s, {rag_avg_tokens:.0f} tokens")
            
            time_change = (rag_avg_time - static_avg_time) / static_avg_time * 100
            token_change = (rag_avg_tokens - static_avg_tokens) / static_avg_tokens * 100
            
            print(f"   üöÄ RAG Effect: {time_change:+.1f}% time, {token_change:+.1f}% tokens")
            
            # Activation analysis
            print(f"\nüîë KEYWORD ACTIVATION ANALYSIS:")
            for entry_name, entry_data in self.travis_lorebook.items():
                print(f"   {entry_name}: {entry_data['activation_count']} activations")
        
        # Save results
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = Path(f"AI/personality/seed_control_results/keyword_rag_test_{timestamp}.json")
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump({
                "experiment_type": "keyword_rag_system",
                "timestamp": datetime.now().isoformat(),
                "travis_lorebook": self.travis_lorebook,
                "all_results": results,
                "static_results": static_results,
                "rag_results": rag_results
            }, f, indent=4)
        
        print(f"\nüíæ Keyword RAG results saved: {results_file}")

if __name__ == "__main__":
    rag_system = LunaKeywordRAGSystem()
    results = rag_system.run_keyword_rag_experiment()
