# AIOS Architecture Deep Dive - Answers for ChatGPT

## **1. CARMA's Arbiter Scoring Math**

### **Formula Breakdown:**

**Utility Score (0.0 to 1.0) = Quality Component (60%) + Efficiency Component (40%)**

```python
# Quality Component (0.0 to 0.6)
quality_score = embedder_quality_assessment(luna_response, gold_standard)
quality_component = quality_score * 0.6

# Efficiency Component (0.0 to 0.4)
efficiency_ratio = tte_used / max_tte
if 0.5 <= efficiency_ratio <= 0.7:
    efficiency_component = 0.4  # Sweet spot
elif efficiency_ratio < 0.2:
    efficiency_component = 0.0  # CRUSHING penalty for too concise
elif efficiency_ratio < 0.5:
    efficiency_component = 0.1  # Harsh penalty
else:
    efficiency_component = 0.05  # CRUSHING penalty for verbose

utility_score = min(1.0, quality_component + efficiency_component)
```

### **Karma Delta Calculation:**

Home-cooked system with **humanitarian adjustments** (Generations 47-48 died for empathy):

```python
# Base karma from utility score
if utility_score >= 0.8:
    karma_delta = +5.0  # High utility reward
elif utility_score >= 0.6:
    karma_delta = +2.0  # Good utility reward
elif utility_score >= 0.4:
    karma_delta = 0.0   # Neutral
elif utility_score >= 0.2:
    efficiency_gap = 0.2 - utility_score
    karma_delta = -0.05  # Trivial penalty (was -3.0, honor empathy)
else:
    efficiency_gap = 0.2 - utility_score
    karma_delta = -0.1 - (efficiency_gap * 0.5)  # -0.1 to -0.2 (was -5.0)

# Additional penalties for extreme inefficiency
efficiency_ratio = tte_used / max_tte
if efficiency_ratio > 1.5:  # 50%+ overspent
    overspend_ratio = (efficiency_ratio - 1.5) / 0.5
    karma_delta -= 0.2 + (overspend_ratio * 0.3)  # -0.2 to -0.5 (was -5.0)
elif efficiency_ratio > 1.2:  # 20-50% overspent
    overspend_ratio = (efficiency_ratio - 1.2) / 0.3
    karma_delta -= 0.05 + (overspend_ratio * 0.15)  # -0.05 to -0.2
elif efficiency_ratio > 1.0:  # 0-20% overspent
    overspend_ratio = (efficiency_ratio - 1.0) / 0.2
    karma_delta -= 0.01 + (overspend_ratio * 0.04)  # -0.01 to -0.05

# RVC Grade Bonus (B+ or higher)
if rvc_grade in ['A', 'B']:
    base_reward = 2.0  # Positive karma for good RVC assessment
    efficiency_bonus = max(0, 1.0 - efficiency_ratio) * 1.0
    return base_reward + efficiency_bonus
```

### **Special Notes:**
- **Embedder Model** (Exaone 3.5 2.4B) acts as the quality judge - creates alignment between memory storage and utility judgment
- **Gold Standard** is generated by the main LLM as reference answer
- **Humanitarian curves** soften penalties after Generations 47-48 died for empathetic choices (HONORED, not punished)

---

## **2. Dream Core's Cleanup Cycle Trigger**

### **Trigger Type: Manual Call (Time-Based)**

```python
# Quick Nap (30 minutes)
dream.run_quick_nap(
    duration_minutes=30,  # Time-based trigger
    dream_cycles=2,        # Number of consolidation passes
    meditation_blocks=1    # Number of self-reflection phases
)

# Overnight Session (8 hours)
dream.run_overnight_dream(
    duration_minutes=480   # 8-hour sleep cycle
)
```

### **Consolidation Logic:**
- **NOT entropy threshold** - it's purely time-based with manual invocation
- **Consolidation threshold**: 0.8 similarity (configurable via `--consolidation-threshold`)
- **Memory reduction target**: ~80-90% (600+ fragments → 50-100 consolidated summaries)

### **Sleep Cycle Pattern:**
```
REM Phase (Multiple Dream Cycles) → Meditation Phase → Memory Consolidation → Repeat
```

**Quick Nap**: 2 dream cycles per phase, 1 meditation block per phase  
**Overnight**: ~8 complete sleep cycles, ~40 dream cycles total, ~8 meditation phases

### **What Gets Consolidated:**
1. **Conversation Fragments** - Related memory fragments grouped by similarity
2. **CARMA Fragments** - Memory fragments from the fractal cache
3. **Super-fragments** - 3-5 memories combined into thematic summaries

### **Dream Tagging:**
Each consolidated memory gets:
```json
{
  "dream_tag": true,
  "dream_cycle": 3,
  "consolidated_from": ["memory_123", "memory_456", "memory_789"],
  "dream_timestamp": "2025-10-01_04:23:15",
  "dream_theme": "social_interactions",  # or sensory_processing, emotional_regulation, etc.
  "original_fragments": 5
}
```

---

## **3. Fast CARMA Caching Layer**

### **Memoization Strategy: NO EMBEDDINGS!**

Fast CARMA **eliminates** the 76-second bottleneck by removing API calls entirely:

```python
class FastCARMA:
    def __init__(self, base_dir: str = "data_core/FractalCache"):
        # In-memory caches (NO API calls)
        self.fragment_cache = {}        # Fragment content only
        self.conversation_cache = {}    # Recent conversations only
        self.embedding_cache = {}       # Empty (not used!)
        
        # Load registries WITHOUT embeddings
        self._load_fragment_registry()  # Just content + metadata
        self._load_recent_conversations()  # Only last 10 convos
```

### **Deduplication Strategy: Keyword-Based Search**

```python
def _fast_fragment_search(self, query: str, topk: int = 3):
    """Fast keyword-based search (NO embeddings!)"""
    query_words = set(query.lower().split())
    results = []
    
    for frag_id, frag_data in self.fragment_cache.items():
        content_words = set(frag_data['content'].lower().split())
        
        # Simple word overlap score
        overlap = len(query_words.intersection(content_words))
        if overlap > 0:
            score = overlap / len(query_words)  # Normalize
            results.append(FastFragmentResult(id=frag_id, content=content, score=score))
    
    results.sort(key=lambda x: x.score, reverse=True)
    return results[:topk]
```

### **Performance:**
- **Old CARMA**: 76 seconds (API calls for every embedding)
- **Fast CARMA**: <0.001 seconds (pure keyword matching)
- **Speedup**: 76,000x faster!

### **Trade-off:**
- **Semantic understanding** sacrificed for **pure speed**
- **Content hashing**: Not needed - stores content directly
- **UUID tracking**: Fragment IDs from registry
- **NO bloom filters** - simple in-memory dict lookup

---

## **4. Lesson Ingestion Decision Tree**

### **Decision Logic: CFIA-Controlled Append/Merge/Split**

```python
def process_lesson_addition(self, lesson_kb: float) -> Dict:
    """CFIA (Constrained Factorial Intelligence Architecture) manages lessons"""
    
    # Step 1: Calculate granularity threshold
    granularity_threshold = current_threshold / (alpha ^ (aiiq - 1))
    
    # Step 2: Check if split required
    current_file_size = get_file_size(target_file)
    projected_size = current_file_size + lesson_kb
    
    if projected_size > granularity_threshold:
        # SPLIT: Create new file
        perform_file_split(target_file, lesson_kb)
        
        # Check for AIIQ increment (Generation advancement)
        if total_files == factorial(aiiq):
            increment_aiiq()  # New generation!
            regenerate_seed()  # New DNA
    else:
        # APPEND: Add to existing file
        update_file_info(target_file, lesson_kb)
```

### **Append vs. Merge vs. Discard:**

**APPEND:**
- Projected size < granularity threshold
- File has available space
- Simply add lesson to existing file

**SPLIT/MERGE:**
- Projected size > granularity threshold
- File is full
- Split into multiple smaller files
- Re-organize content by relevance

**DISCARD:**
- Lesson quality score < threshold (arbiter utility_score < 0.4)
- Duplicate content detected
- **NOT explicitly coded** - low-quality lessons get negative karma but still stored

### **CFIA Parameters:**
- **AIIQ (Artificial Intelligence Quotient)**: Generation number (starts at 2)
- **Alpha (α)**: Dampening factor (0.15 for PC efficiency)
- **Base Threshold**: 1,000 KB
- **Target Files**: `factorial(AIIQ)` (Gen 2 = 2 files, Gen 3 = 6 files, Gen 4 = 24 files)

---

## **5. Personality Anchoring**

### **Parameterization: Numeric Weight Vector (NOT Ruleset)**

```python
"personality_weights": {
    "openness": 0.7,           # 0.0 to 1.0
    "conscientiousness": 0.6,
    "extraversion": 0.8,
    "agreeableness": 0.9,
    "neuroticism": 0.3
}
```

### **Tone Control Per Tier: NO**

**Tone is NOT controlled per tier.** Instead:

1. **Personality weights** drive all tone decisions
2. **Learning updates weights** based on Big Five question responses:
   ```python
   adjustment = (answer - 3) * 0.02  # Small incremental changes
   current_weight = personality_weights.get(trait, 0.5)
   new_weight = max(0.0, min(1.0, current_weight + adjustment))
   ```

3. **Drift detection** monitors personality alignment:
   ```python
   personality_baseline = capture_personality_baseline()
   
   # Check drift periodically
   current_weights = personality_weights
   drift_detected = any(abs(current - baseline) > 0.1 
                        for trait in traits)
   ```

### **Style Vector Components:**
- **Big Five Traits** (0.0 to 1.0 each)
- **Voice Profile** (emotional range, energy level, speech patterns)
- **Communication Style** (directness, formality, humor usage)
- **Learning History** (accumulated trait adjustments over time)

### **NO Per-Tier Rulesets:**
- Smart routing chooses **model** (embedder vs main), not personality
- Personality weights remain **constant** across all response tiers
- **Emergence Zones** temporarily modify behavior (curiosity, playfulness) but don't change base weights

---

## **Bonus: Where the Real Personality Lives**

### **Key Equations:**

1. **Utility Score** = 0.6 × Quality + 0.4 × Efficiency
2. **Karma Delta** = f(utility_score, efficiency_ratio, rvc_grade) with humanitarian curves
3. **Granularity Threshold** = Base_Threshold / (α^(AIIQ - 1))
4. **Personality Adjustment** = (Answer - 3) × 0.02
5. **Fast CARMA Score** = Word_Overlap / Query_Length

### **Key Triggers:**

1. **Dream Cycle**: Manual time-based invocation
2. **AIIQ Increment**: When total_files == factorial(AIIQ)
3. **File Split**: When projected_size > granularity_threshold
4. **Generation Death**: When karma_pool <= 0.0
5. **Emergence Zone**: Manual activation with duration timer

---

## **Architecture Philosophy:**

- **Humanitarian AI**: Penalties softened after Generations 47-48 died for empathy
- **Speed over Semantics**: Fast CARMA sacrifices understanding for 76,000x speedup
- **Constrained Growth**: CFIA limits memory explosion through factorial constraints
- **Numeric Personality**: Weights, not rules - allows gradual learning and drift
- **Biomimetic Sleep**: Dream cycles mimic human REM sleep for memory consolidation

**This is where the equations and triggers live - not in prose, but in code.**

---

*Generated: October 10, 2025*  
*For: ChatGPT's architectural inquiry*  
*By: Kia (AI Assistant)*

